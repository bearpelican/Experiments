{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenet Validation Techniques Compared - Square VS Rectangle VS TTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compare the different validation techniques on a pretrained resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, shutil, time, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import Sampler\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "data = Path.home()/'data/imagenet'\n",
    "workers = 7\n",
    "valdir = data/'validation'\n",
    "batch_size = 64\n",
    "fp16 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create Image to Aspect ratio mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: sort images by aspect ratio\n",
    "def sort_ar(valdir):\n",
    "    idx2ar_file = data/'sorted_idxar.p'\n",
    "    if os.path.isfile(idx2ar_file): return pickle.load(open(idx2ar_file, 'rb'))\n",
    "    print('Creating AR indexes. Please be patient this may take a couple minutes...')\n",
    "    val_dataset = datasets.ImageFolder(valdir)\n",
    "    sizes = [img[0].size for img in tqdm(val_dataset, total=len(val_dataset))]\n",
    "    idx_ar = [(i, round(s[0]/s[1], 5)) for i,s in enumerate(sizes)]\n",
    "    sorted_idxar = sorted(idx_ar, key=lambda x: x[1])\n",
    "    pickle.dump(sorted_idxar, open(idx2ar_file, 'wb'))\n",
    "    return sorted_idxar\n",
    "\n",
    "# Step 2: chunk images by batch size. This way we can crop each image to the batch aspect ratio mean \n",
    "def chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return (l[i:i+n] for i in range(0, len(l), n))\n",
    "\n",
    "# Step 3: map image index to batch aspect ratio mean so our transform function knows where to crop\n",
    "def map_idx2ar(idx_ar_sorted, batch_size):\n",
    "    ar_chunks = list(chunks(idx_ar_sorted, batch_size))\n",
    "    idx2ar = {}\n",
    "    ar_means = []\n",
    "    for chunk in ar_chunks:\n",
    "        idxs, ars = list(zip(*chunk))\n",
    "        mean = round(np.mean(ars), 5)\n",
    "        ar_means.append(mean)\n",
    "        for idx in idxs:\n",
    "            idx2ar[idx] = mean\n",
    "    return idx2ar, ar_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ar_sorted = sort_ar(valdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR just download precomputed imagenet sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2ar_path = data/'sorted_idxar.p'\n",
    "url = 'https://s3-us-west-2.amazonaws.com/ashaw-fastai-imagenet/sorted_idxar.p'\n",
    "if not idx2ar_path.exists(): urllib.request.urlretrieve(url, idx2ar_path)\n",
    "idx_ar_sorted = sort_ar(valdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Rectangular Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValDataset(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None, target_transform=None):\n",
    "        super().__init__(root, transform, target_transform)\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.imgs[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            for tfm in self.transform:\n",
    "                if isinstance(tfm, RectangularCropTfm): sample = tfm(sample, index)\n",
    "                else: sample = tfm(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "    \n",
    "# Essentially a sequential sampler\n",
    "class SequentialIndexSampler(Sampler):\n",
    "    def __init__(self, indices): self.indices = indices\n",
    "    def __len__(self): return len(self.indices)\n",
    "    def __iter__(self): return iter(self.indices)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectangularCropTfm(object):\n",
    "    def __init__(self, idx2ar, target_size):\n",
    "        self.idx2ar, self.target_size = idx2ar, target_size\n",
    "    def __call__(self, img, idx):\n",
    "        target_ar = self.idx2ar[idx]\n",
    "        if target_ar < 1: \n",
    "            w = int(self.target_size/target_ar)\n",
    "            size = (w//8*8, self.target_size)\n",
    "        else: \n",
    "            h = int(self.target_size*target_ar)\n",
    "            size = (self.target_size, h//8*8)\n",
    "        return transforms.functional.center_crop(img, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Validation Function (with TTA enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, aug_loader=None, num_augmentations=0):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "\n",
    "    val_iter = iter(val_loader)\n",
    "    aug_iters = [iter(aug_loader) for i in range(num_augmentations)]\n",
    "    prec5_arr = []\n",
    "    for i in range(len(val_loader)):\n",
    "        def get_output(dl_iter):\n",
    "            input,target = next(dl_iter)\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "            if fp16: input = input.half()\n",
    "\n",
    "            # compute output\n",
    "            with torch.no_grad():\n",
    "                output = model(Variable(input))\n",
    "                loss = criterion(output, Variable(target))\n",
    "            return output, loss, input, target\n",
    "        \n",
    "        # Normal Validation\n",
    "        output,loss,input,target = get_output(val_iter)\n",
    "        \n",
    "        # TTA\n",
    "        for aug_iter in aug_iters:\n",
    "            o,l,_,_ = get_output(aug_iter)\n",
    "            output.add_(o)\n",
    "            loss.add_(l)\n",
    "        loss.div_(num_augmentations+1)\n",
    "        \n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        reduced_loss = loss.data\n",
    "            \n",
    "        losses.update(to_python_float(reduced_loss), input.size(0))\n",
    "        top1.update(to_python_float(prec1), input.size(0))\n",
    "        top5.update(to_python_float(prec5), input.size(0))\n",
    "        prec5_arr.append(to_python_float(prec5))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if ((i+1)%100 == 0) or ((i+1) == len(val_loader)):\n",
    "            output = ('Test: [{0}/{1}]\\t' \\\n",
    "                    + 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n",
    "                    + 'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' \\\n",
    "                    + 'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t' \\\n",
    "                    + 'Prec@5 {top5.val:.3f} ({top5.avg:.3f})').format(\n",
    "                    i+1, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                    top1=top1, top5=top5)\n",
    "            print(output)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    print(f'Total Time:{float(time_diff.total_seconds() / 3600.0)}\\t Top 5 Accuracy: {top5.avg:.3f}\\n')\n",
    "    print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
    "\n",
    "    return prec5_arr\n",
    "\n",
    "# item() is a recent addition, so this helps with backward compatibility.\n",
    "def to_python_float(t):\n",
    "    if hasattr(t, 'item'): return t.item()\n",
    "    else: return t[0]\n",
    "    \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self): self.reset()\n",
    "    def reset(self): self.val = self.avg = self.sum = self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Get pretrained resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet\n",
    "model = resnet.resnet50(pretrained=True)\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "if fp16: model = model.half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global dataset settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_bs = 64\n",
    "target_size = 288\n",
    "\n",
    "idx_sorted, _ = zip(*idx_ar_sorted)\n",
    "idx2ar, ar_means = map_idx2ar(idx_ar_sorted, val_bs)\n",
    "val_sampler_ar = SequentialIndexSampler(idx_sorted)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "tensor_tfm = [transforms.ToTensor(), normalize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally: Compare different Validations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Square Validation Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the validation technique used in fast.ai's original [DAWNBenchmark](https://dawn.cs.stanford.edu/benchmark/ImageNet/train.html)  \n",
    "Resize Image 1.14x -> Crop to target size (288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100/782]\tTime 0.074 (0.130)\tLoss 1.4658 (1.0240)\tPrec@1 59.375 (74.469)\tPrec@5 85.938 (92.047)\n",
      "Test: [200/782]\tTime 0.055 (0.114)\tLoss 0.4976 (0.9866)\tPrec@1 85.938 (75.430)\tPrec@5 100.000 (92.594)\n",
      "Test: [300/782]\tTime 0.055 (0.110)\tLoss 0.9302 (0.9541)\tPrec@1 75.000 (76.198)\tPrec@5 93.750 (93.010)\n",
      "Test: [400/782]\tTime 0.064 (0.107)\tLoss 0.7817 (0.9018)\tPrec@1 81.250 (77.461)\tPrec@5 95.312 (93.516)\n",
      "Test: [500/782]\tTime 0.056 (0.108)\tLoss 0.3689 (0.9054)\tPrec@1 93.750 (77.328)\tPrec@5 98.438 (93.653)\n",
      "Test: [600/782]\tTime 0.056 (0.108)\tLoss 1.2910 (0.9347)\tPrec@1 70.312 (76.797)\tPrec@5 90.625 (93.206)\n",
      "Test: [700/782]\tTime 0.055 (0.107)\tLoss 0.4583 (0.9248)\tPrec@1 85.938 (76.944)\tPrec@5 96.875 (93.366)\n",
      "Test: [782/782]\tTime 1.049 (0.108)\tLoss 1.2539 (0.9217)\tPrec@1 62.500 (76.914)\tPrec@5 93.750 (93.430)\n",
      "Total Time:0.02348072333333333\t Top 5 Accuracy: 93.430\n",
      "\n",
      " * Prec@1 76.914 Prec@5 93.430\n"
     ]
    }
   ],
   "source": [
    "val_tfms = [transforms.Resize(int(target_size*1.14)), transforms.CenterCrop(target_size)] + tensor_tfm\n",
    "val_dataset = datasets.ImageFolder(valdir,  transforms.Compose(val_tfms))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=val_bs, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True, sampler=val_sampler_ar)\n",
    "\n",
    "orig_prec5 = validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Fast.Ai Rectangular Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform validation with rectangular images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100/782]\tTime 0.100 (0.329)\tLoss 1.4004 (1.0478)\tPrec@1 59.375 (76.172)\tPrec@5 87.500 (93.422)\n",
      "Test: [200/782]\tTime 0.058 (0.268)\tLoss 0.5542 (1.0024)\tPrec@1 85.938 (76.594)\tPrec@5 100.000 (93.539)\n",
      "Test: [300/782]\tTime 0.075 (0.234)\tLoss 0.9624 (0.9680)\tPrec@1 76.562 (76.948)\tPrec@5 92.188 (93.698)\n",
      "Test: [400/782]\tTime 0.071 (0.208)\tLoss 0.9170 (0.9237)\tPrec@1 79.688 (77.914)\tPrec@5 93.750 (94.078)\n",
      "Test: [500/782]\tTime 0.071 (0.189)\tLoss 0.3828 (0.9363)\tPrec@1 90.625 (77.713)\tPrec@5 98.438 (94.056)\n",
      "Test: [600/782]\tTime 0.071 (0.177)\tLoss 1.2441 (0.9607)\tPrec@1 70.312 (77.188)\tPrec@5 93.750 (93.693)\n",
      "Test: [700/782]\tTime 0.080 (0.174)\tLoss 0.5312 (0.9544)\tPrec@1 85.938 (77.304)\tPrec@5 95.312 (93.846)\n",
      "Test: [782/782]\tTime 1.264 (0.204)\tLoss 0.8638 (0.9548)\tPrec@1 75.000 (77.354)\tPrec@5 93.750 (93.914)\n",
      "Total Time:0.04431332388888889\t Top 5 Accuracy: 93.914\n",
      "\n",
      " * Prec@1 77.354 Prec@5 93.914\n"
     ]
    }
   ],
   "source": [
    "val_ar_tfms = [transforms.Resize(int(target_size*1.14)), RectangularCropTfm(idx2ar, target_size)]\n",
    "val_dataset_rect = ValDataset(valdir, val_ar_tfms+tensor_tfm)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset_rect, batch_size=val_bs, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True, sampler=val_sampler_ar)\n",
    "\n",
    "rect_prec5 = validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Square VS Rectangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Square Validation \n",
    "    * Top 5 - 93.430\n",
    "    * Total Time - 0.0235\n",
    "* Rectangular Validation\n",
    "    * Top 5 - 93.914\n",
    "    * Total Time - 0.0443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_mean(array, size=10): return [np.array(c).mean() for c in chunks(array, 100)]\n",
    "batch_means = batch_mean(ar_means)\n",
    "rect_prec5_mean = batch_mean(rect_prec5)\n",
    "orig_prec5_mean = batch_mean(orig_prec5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalValidation</th>\n",
       "      <th>RectangularValidation</th>\n",
       "      <th>AR Mean</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.046875</td>\n",
       "      <td>93.421875</td>\n",
       "      <td>0.704379</td>\n",
       "      <td>1.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.140625</td>\n",
       "      <td>93.656250</td>\n",
       "      <td>0.806230</td>\n",
       "      <td>0.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.843750</td>\n",
       "      <td>94.015625</td>\n",
       "      <td>1.072789</td>\n",
       "      <td>0.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.031250</td>\n",
       "      <td>95.218750</td>\n",
       "      <td>1.301455</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.203125</td>\n",
       "      <td>93.968750</td>\n",
       "      <td>1.333330</td>\n",
       "      <td>-0.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.968750</td>\n",
       "      <td>91.875000</td>\n",
       "      <td>1.333330</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>94.328125</td>\n",
       "      <td>94.765625</td>\n",
       "      <td>1.406869</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93.978659</td>\n",
       "      <td>94.493140</td>\n",
       "      <td>1.585774</td>\n",
       "      <td>0.514482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OriginalValidation  RectangularValidation   AR Mean  Difference\n",
       "0           92.046875              93.421875  0.704379    1.375000\n",
       "1           93.140625              93.656250  0.806230    0.515625\n",
       "2           93.843750              94.015625  1.072789    0.171875\n",
       "3           95.031250              95.218750  1.301455    0.187500\n",
       "4           94.203125              93.968750  1.333330   -0.234375\n",
       "5           90.968750              91.875000  1.333330    0.906250\n",
       "6           94.328125              94.765625  1.406869    0.437500\n",
       "7           93.978659              94.493140  1.585774    0.514482"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'OriginalValidation': orig_prec5_mean, \n",
    "     'RectangularValidation': rect_prec5_mean, \n",
    "     'AR Mean': batch_means,\n",
    "     'Difference': np.array(rect_prec5_mean)-np.array(orig_prec5_mean)}\n",
    "df = pd.DataFrame(data=d); df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that rectangular validation outperforms the original when the aspect ratio is farther away from 1 (square crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate with TTA (Test Time Augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 4 random crops + original validation image and averages the predictions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_scale = 0.5\n",
    "trn_tfms = [\n",
    "        transforms.RandomResizedCrop(target_size, scale=(min_scale, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ] + tensor_tfm\n",
    "aug_dataset = datasets.ImageFolder(valdir, transforms.Compose(trn_tfms))\n",
    "\n",
    "val_tfms = [transforms.Resize(int(target_size*1.14)), transforms.CenterCrop(target_size)] + tensor_tfm\n",
    "val_dataset = datasets.ImageFolder(valdir,  transforms.Compose(val_tfms))\n",
    "\n",
    "aug_loader = torch.utils.data.DataLoader(\n",
    "    aug_dataset, batch_size=val_bs, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True, sampler=val_sampler_ar)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=val_bs, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True, sampler=val_sampler_ar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100/782]\tTime 0.393 (0.494)\tLoss 1.4531 (1.0414)\tPrec@1 59.375 (76.203)\tPrec@5 87.500 (93.359)\n",
      "Test: [200/782]\tTime 0.368 (0.461)\tLoss 0.5205 (1.0151)\tPrec@1 85.938 (76.742)\tPrec@5 100.000 (93.555)\n",
      "Test: [300/782]\tTime 0.348 (0.461)\tLoss 0.9717 (0.9848)\tPrec@1 76.562 (77.208)\tPrec@5 92.188 (93.693)\n",
      "Test: [400/782]\tTime 0.349 (0.454)\tLoss 0.8115 (0.9328)\tPrec@1 82.812 (78.309)\tPrec@5 96.875 (94.105)\n",
      "Test: [500/782]\tTime 0.463 (0.458)\tLoss 0.4075 (0.9356)\tPrec@1 95.312 (78.256)\tPrec@5 98.438 (94.194)\n",
      "Test: [600/782]\tTime 0.464 (0.456)\tLoss 1.3145 (0.9632)\tPrec@1 73.438 (77.776)\tPrec@5 93.750 (93.831)\n",
      "Test: [700/782]\tTime 0.368 (0.453)\tLoss 0.4526 (0.9523)\tPrec@1 87.500 (77.931)\tPrec@5 98.438 (94.011)\n",
      "Test: [782/782]\tTime 0.078 (0.447)\tLoss 1.1768 (0.9465)\tPrec@1 68.750 (78.010)\tPrec@5 87.500 (94.094)\n",
      "Total Time:0.09710323\t Top 5 Accuracy: 94.094\n",
      "\n",
      " * Prec@1 78.010 Prec@5 94.094\n"
     ]
    }
   ],
   "source": [
    "tta_prec5 = validate(val_loader, model, criterion, aug_loader=aug_loader, num_augmentations=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate with TTA and Rectangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 4 random crops + recangular validation image and averages the predictions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100/782]\tTime 0.450 (0.533)\tLoss 1.4590 (1.0473)\tPrec@1 60.938 (76.484)\tPrec@5 87.500 (93.344)\n",
      "Test: [200/782]\tTime 0.404 (0.511)\tLoss 0.5361 (1.0162)\tPrec@1 92.188 (77.000)\tPrec@5 100.000 (93.594)\n",
      "Test: [300/782]\tTime 0.384 (0.507)\tLoss 1.0049 (0.9867)\tPrec@1 75.000 (77.469)\tPrec@5 92.188 (93.771)\n",
      "Test: [400/782]\tTime 0.500 (0.504)\tLoss 0.8462 (0.9368)\tPrec@1 84.375 (78.496)\tPrec@5 96.875 (94.160)\n",
      "Test: [500/782]\tTime 0.408 (0.505)\tLoss 0.3413 (0.9410)\tPrec@1 93.750 (78.428)\tPrec@5 98.438 (94.219)\n",
      "Test: [600/782]\tTime 0.352 (0.501)\tLoss 1.2451 (0.9683)\tPrec@1 71.875 (77.893)\tPrec@5 93.750 (93.872)\n",
      "Test: [700/782]\tTime 0.431 (0.498)\tLoss 0.4773 (0.9577)\tPrec@1 87.500 (78.013)\tPrec@5 98.438 (94.069)\n",
      "Test: [782/782]\tTime 0.114 (0.494)\tLoss 1.1299 (0.9529)\tPrec@1 68.750 (78.090)\tPrec@5 93.750 (94.168)\n",
      "Total Time:0.10739349833333334\t Top 5 Accuracy: 94.168\n",
      "\n",
      " * Prec@1 78.090 Prec@5 94.168\n"
     ]
    }
   ],
   "source": [
    "min_scale = 0.5\n",
    "trn_tfms = [\n",
    "        transforms.RandomResizedCrop(target_size, scale=(min_scale, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ] + tensor_tfm\n",
    "aug_dataset = datasets.ImageFolder(valdir, transforms.Compose(trn_tfms))\n",
    "\n",
    "aug_loader = torch.utils.data.DataLoader(\n",
    "    aug_dataset, batch_size=val_bs, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True, sampler=val_sampler_ar)\n",
    "\n",
    "val_ar_tfms = [transforms.Resize(int(target_size*1.14)), RectangularCropTfm(idx2ar, target_size)]\n",
    "val_dataset_rect = ValDataset(valdir, val_ar_tfms+tensor_tfm)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset_rect, batch_size=val_bs, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True, sampler=val_sampler_ar)\n",
    "\n",
    "tta_rect_prec5 = validate(val_loader, model, criterion, aug_loader=aug_loader, num_augmentations=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing all the Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Square Validation \n",
    "    * Top 5 - 93.430\n",
    "    * Total Time - 0.0235\n",
    "* Rectangular Validation\n",
    "    * Top 5 - 93.914\n",
    "    * Total Time - 0.0443\n",
    "* TTA\n",
    "    * Top 5 - 94.094\n",
    "    * Total Time - 0.0971\n",
    "* TTA + Rectangles\n",
    "    * Top 5 - 94.168\n",
    "    * Total Time - 0.1074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_mean(array, size=10): return [np.array(c).mean() for c in chunks(array, 100)]\n",
    "batch_means = batch_mean(ar_means)\n",
    "rect_prec5_mean = batch_mean(rect_prec5)\n",
    "orig_prec5_mean = batch_mean(orig_prec5)\n",
    "tta_prec5_mean = batch_mean(tta_prec5)\n",
    "tta_rect_prec5_mean = batch_mean(tta_rect_prec5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Validation</th>\n",
       "      <th>Rectangular Validation</th>\n",
       "      <th>TTA Validation</th>\n",
       "      <th>TTA + Rectangular Validation</th>\n",
       "      <th>AR Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.046875</td>\n",
       "      <td>93.421875</td>\n",
       "      <td>93.359375</td>\n",
       "      <td>93.343750</td>\n",
       "      <td>0.704379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.140625</td>\n",
       "      <td>93.656250</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>93.843750</td>\n",
       "      <td>0.806230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.843750</td>\n",
       "      <td>94.015625</td>\n",
       "      <td>93.968750</td>\n",
       "      <td>94.125000</td>\n",
       "      <td>1.072789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.031250</td>\n",
       "      <td>95.218750</td>\n",
       "      <td>95.343750</td>\n",
       "      <td>95.328125</td>\n",
       "      <td>1.301455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.203125</td>\n",
       "      <td>93.968750</td>\n",
       "      <td>94.546875</td>\n",
       "      <td>94.453125</td>\n",
       "      <td>1.333330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.968750</td>\n",
       "      <td>91.875000</td>\n",
       "      <td>92.015625</td>\n",
       "      <td>92.140625</td>\n",
       "      <td>1.333330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>94.328125</td>\n",
       "      <td>94.765625</td>\n",
       "      <td>95.093750</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>1.406869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93.978659</td>\n",
       "      <td>94.493140</td>\n",
       "      <td>94.740854</td>\n",
       "      <td>95.007622</td>\n",
       "      <td>1.585774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original Validation  Rectangular Validation  TTA Validation  \\\n",
       "0            92.046875               93.421875       93.359375   \n",
       "1            93.140625               93.656250       93.750000   \n",
       "2            93.843750               94.015625       93.968750   \n",
       "3            95.031250               95.218750       95.343750   \n",
       "4            94.203125               93.968750       94.546875   \n",
       "5            90.968750               91.875000       92.015625   \n",
       "6            94.328125               94.765625       95.093750   \n",
       "7            93.978659               94.493140       94.740854   \n",
       "\n",
       "   TTA + Rectangular Validation   AR Mean  \n",
       "0                     93.343750  0.704379  \n",
       "1                     93.843750  0.806230  \n",
       "2                     94.125000  1.072789  \n",
       "3                     95.328125  1.301455  \n",
       "4                     94.453125  1.333330  \n",
       "5                     92.140625  1.333330  \n",
       "6                     95.250000  1.406869  \n",
       "7                     95.007622  1.585774  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Original Validation': orig_prec5_mean, \n",
    "     'Rectangular Validation': rect_prec5_mean, \n",
    "     'TTA Validation': tta_prec5_mean, \n",
    "     'TTA + Rectangular Validation': tta_rect_prec5_mean, \n",
    "     'AR Mean': batch_means}\n",
    "df = pd.DataFrame(data=d); df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
